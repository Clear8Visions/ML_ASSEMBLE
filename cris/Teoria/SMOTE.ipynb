{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/ \n",
    "\n",
    "# SMOTE per la classificazione sbilanciata con Python  \n",
    "\n",
    "### Introduzione  \n",
    "I set di dati sbilanciati rappresentano una sfida comune per i professionisti dell'apprendimento automatico nei problemi di classificazione binaria.  \n",
    "\n",
    "Questo scenario si verifica spesso in applicazioni aziendali pratiche come il \n",
    "- rilevamento delle frodi, \n",
    "- il filtro antispam, \n",
    "- la scoperta di malattie rare ,\n",
    "- il rilevamento di guasti hardware.  \n",
    "\n",
    "Per affrontare questo problema, una tecnica popolare è la tecnica di sovracampionamento sintetico delle minoranze (SMOTE).  \n",
    "\n",
    "**SMOTE** (*Synthetic Minority Oversampling Technique*) è specificamente progettato per affrontare i set di dati sbilanciati **genera**ndo **campioni sintetici per la classe di minoranza**.\n",
    "Mitigando i pregiudizi e catturando le caratteristiche importanti della classe di minoranza, SMOTE contribuisce a previsioni più accurate e a migliori prestazioni del modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual è la funzione di Smote?  \n",
    "1. **Identifica lo squilibrio**:  \n",
    "    Si inizia riconoscendo che i dati appartengono a una classe minoritaria, come i casi di malattie rare in un set di dati medici.\n",
    "2. **Crea** specificamente nuovi punti **dati** **per** la **classe minoritaria**,  \n",
    "    non per la maggioranza.\n",
    "3. **Crea campioni sintetici**:  \n",
    "    Analizza i punti dati delle minoranze esistenti e ne genera di nuovi simili.\n",
    "4. **Aumentare la minoranza**:  \n",
    "    Aggiungendo questi campioni sintetici, SMOTE bilancia i dati, dando al modello una migliore possibilità di apprendere la classe di minoranza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il paradosso dell'accuratezza\n",
    "\n",
    "Supponiamo che tu stia lavorando su un problema di rilevamento delle frodi basato sull'assicurazione sanitaria.  \n",
    "\n",
    "In tali problemi, generalmente osserviamo che su 100 richieste di risarcimento assicurativo, 99 di esse non sono fraudolente e 1 è fraudolenta. Pertanto, un modello di classificatore binario non deve essere un modello complesso per prevedere tutti i risultati come 0, ovvero non fraudolenti e raggiungere una grande precisione del 99%.  \n",
    "\n",
    "Chiaramente, in questi casi in cui la distribuzione delle classi è distorta, la metrica di accuratezza è distorta e non preferibile.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestione dei dati sbilanciati  \n",
    "Il ricampionamento dei dati è uno degli approcci più comunemente preferiti per gestire un set di dati sbilanciato.  \n",
    "\n",
    "Esistono sostanzialmente due tipi di metodi per questo: \n",
    "1. Sottocampionamento, \n",
    "2. Sovracampionamento. \n",
    "\n",
    "Nella maggior parte dei casi, il *sovracampionamento è preferito alle tecniche di sottocampionamento*.  \n",
    "\n",
    "Il motivo è che nel sottocampionamento tendiamo a rimuovere i casi dai dati che potrebbero contenere alcune informazioni importanti.  \n",
    "Per questo motivo tratteremo di alcune tecniche speciali di sovracampionamento dell'aumento dei dati: SMOTE e le sue controparti correlate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedura di lavoro\n",
    "\n",
    "All'inizio il totale n. di osservazioni di sovracampionamento, N è impostato.  \n",
    "\n",
    "Generalmente, viene selezionato in modo che la distribuzione della classe binaria sia 1:1.  \n",
    "Ma questo potrebbe essere regolato in base alle necessità.  \n",
    "\n",
    "Quindi l'iterazione inizia selezionando prima un'istanza di classe positiva a caso.  \n",
    "\n",
    "Successivamente, si ottengono i KNN (per impostazione predefinita 5) per quell'istanza.  \n",
    "\n",
    "Alla fine, N di queste K istanze viene scelta per interpolare nuove istanze sintetiche. Per fare ciò, utilizzando qualsiasi metrica di distanza, viene calcolata la differenza di distanza tra il vettore di elementi e i suoi vicini.  \n",
    "\n",
    "Ora, questa differenza viene moltiplicata per qualsiasi valore casuale in (0,1] e viene aggiunta al vettore di funzionalità precedente. Questo è rappresentato pittoricamente di seguito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/77417image1.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/77417image1.webp\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# oversampling the train dataset using SMOTE\n",
    "smt = SMOTE()\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_sm)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiti di SMOTE  \n",
    "1. Le istanze sintetiche generate sono nella stessa direzione, cioè collegate da una linea artificiale le sue istanze diagonali. Questo a sua volta complica la superficie decisionale generata da pochi algoritmi di classificazione.\n",
    "2. SMOTE tende a creare un grande no. di punti dati rumorosi nello spazio delle funzionalità."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN: Approccio di campionamento sintetico adattivo\n",
    "ADASYN è una forma generalizzata dell'algoritmo SMATE. Questo algoritmo mira anche a sovracampionare la classe minoritaria generando istanze sintetiche per essa. Ma la differenza qui è che considera la distribuzione della densità, rio che decide il n. di istanze sintetiche generate per campioni difficili da apprendere. Per questo motivo, aiuta a modificare in modo adattivo i limiti decisionali in base ai campioni difficili da imparare. Questa è la differenza principale rispetto a SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "# Counting the number of instances in each class before oversampling\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# Oversampling the train dataset using ADASYN\n",
    "ada = ADASYN(random_state=130)\n",
    "X_train_ada, y_train_ada = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "# Counting the number of instances in each class after oversampling\n",
    "counter = Counter(y_train_ada)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECNICHE DI IBRIDAZIONE  \n",
    "Le tecniche di ibridazione comportano la combinazione di tecniche di sottocampionamento e sovracampionamento.  \n",
    "Questa operazione viene eseguita per ottimizzare le prestazioni dei modelli di classificatore per i campioni creati come parte di queste tecniche.\n",
    "### SMOTE + Tomek Links  \n",
    "Tecnica ibrida che mira a pulire i punti dati sovrapposti per ciascuna delle classi distribuite nello spazio campionario.  \n",
    "\n",
    "**Dopo** che il sovracampionamento è stato effettuato da **SMOTE**, **i cluster di classi potrebbero invadere lo spazio l'uno dell'altro**.  \n",
    "\n",
    "**Di conseguenza**, il modello di classificatore sarà in **overfitting**.  \n",
    "\n",
    "Ora, i collegamenti Tomek sono i campioni accoppiati di classe opposta che sono i vicini più prossimi l'uno all'altro.  \n",
    "\n",
    "Pertanto, la maggior parte delle osservazioni di classe da questi collegamenti vengono rimosse in quanto si ritiene che aumenti la separazione di classe vicino ai confini decisionali.  \n",
    "\n",
    "Ora, per ottenere migliori cluster di classi, i collegamenti Tomek vengono applicati a campioni di classi di minoranza sovracampionate eseguite da SMOTE. Quindi, invece di rimuovere le osservazioni solo dalla classe di maggioranza, generalmente rimuoviamo entrambe le osservazioni di classe dai collegamenti di Tomek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "\n",
    "# Counting the number of instances in each class before oversampling\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# Oversampling the train dataset using SMOTE + Tomek\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X_train, y_train)\n",
    "\n",
    "# Counting the number of instances in each class after oversampling\n",
    "counter = Counter(y_train_smtom)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + ENN\n",
    "\n",
    "Altra tecnica ibrida in cui più no. delle osservazioni vengono rimossi dallo spazio campionario.  \n",
    "\n",
    "In questo caso, l'ENN è un'altra tecnica di sottocampionamento in cui vengono stimati i vicini più prossimi di ciascuna della classe di maggioranza. Se i vicini più prossimi classificano erroneamente quella particolare istanza della classe di maggioranza, tale istanza viene eliminata.\n",
    "\n",
    "L'integrazione di questa tecnica con i dati sovracampionati eseguiti da SMOTE aiuta a eseguire un'ampia pulizia dei dati. Qui, in caso di errata classificazione da parte di NN, i campioni di entrambe le classi vengono rimossi. **Ciò si traduce in una separazione delle classi più chiara e concisa.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "\n",
    "# Counting the number of instances in each class before oversampling\n",
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# Oversampling the train dataset using SMOTE + Tomek\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X_train, y_train)\n",
    "\n",
    "# Counting the number of instances in each class after oversampling\n",
    "counter = Counter(y_train_smtom)\n",
    "print('After', counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/19616image7.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/19616image7.webp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi delle prestazioni dopo il ricampionamento  \n",
    "\n",
    "Per comprendere l'effetto del sovracampionamento, utilizzerò un set di dati sull'abbandono dei clienti bancari.  \n",
    "\n",
    "Si tratta di un dato sbilanciato in cui la variabile target, il churn ha l'81,5% di clienti che non abbandonano e il 18,5% di clienti che hanno abbandonato.\n",
    "\n",
    "È stata effettuata un'analisi comparativa sul set di dati utilizzando 3 modelli di classificazione: regressione logistica, albero decisionale e foresta casuale.  \n",
    "\n",
    "Come illustrato in precedenza, verrà ignorata la metrica di accuratezza per valutare le prestazioni del classificatore su questo set di dati sbilanciato. Qui, ci interessa di più sapere quali sono i clienti che sforneranno nei prossimi mesi.  \n",
    "\n",
    "In questo modo, ci concentreremo su metriche come: \n",
    "- $Precisione=\\frac{\\text{Vero Positivi}}{\\text{Vero Positivi + Falsi Positivi}}$\n",
    "- $Richiamo=\\frac{\\text{Vero Positivi}}{\\text{Vero Positivi + Falsi Negativi}}$, \n",
    "- $Punteggio F1=2 \\cdot \\frac{Precisione \\cdot Richiamo}{\\text{Precisione + Richiamo}}$  \n",
    "\n",
    "per comprendere le prestazioni dei classificatori per determinare correttamente quali clienti abbandoneranno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/47903image8.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/47903image8.webp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sul **set di dati sbilanciato** effettivo, **tutti i modelli** di classificatori non sono stati in grado di generalizzare bene sulla classe di minoranza rispetto alla classe di maggioranza. Di conseguenza, la maggior parte dei campioni di classe negativi sono stati classificati correttamente.  \n",
    "\n",
    "A causa di ciò, c'era meno FP rispetto a più FN.  \n",
    "\n",
    "Dopo il sovracampionamento, si osserva un chiaro aumento del richiamo sui dati del test. Per capirlo meglio, di seguito viene mostrato un barplot comparativo per tutti e 3 i modelli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/24531image9.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/24531image9.webp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'è una diminuzione della precisione, ma ottenendo un richiamo molto che soddisfa l'obiettivo di qualsiasi problema di classificazione binaria. Inoltre, il punteggio AUC-ROC e F1 per ciascun modello rimangono più o meno gli stessi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
